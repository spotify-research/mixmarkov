{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBMT dataset: prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mixmarkov import CTMC, GamMixCTMC, FiniteMixCTMC, summarize_sequences\n",
    "from mixmarkov.utils import draw_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "vecs_year = rng.normal(size=(3, 5))\n",
    "year_map = {\n",
    "    \"1985-1989\": vecs_year[0],\n",
    "    \"1990-1994\": vecs_year[1],\n",
    "    \"1995-1998\": vecs_year[2],\n",
    "}\n",
    "\n",
    "vecs_agecl = rng.normal(size=(3, 5))\n",
    "agecl_map = {\n",
    "    \"<=20\": vecs_agecl[0],\n",
    "    \"20-40\": vecs_agecl[1],\n",
    "    \">40\": vecs_agecl[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list()\n",
    "feats = list()\n",
    "\n",
    "with open(\"../data/ebmt.dat\") as f:\n",
    "    #next(f)  # First line is header.\n",
    "    cur = None\n",
    "    for row in csv.DictReader(f, delimiter=\" \"):\n",
    "        #idx, src, dst, _, start, stop, _, status, match, proph, year, agecls = line.strip().split(\" \")\n",
    "        src = int(row[\"from\"]) - 1\n",
    "        dst = int(row[\"to\"]) - 1\n",
    "        if row[\"id\"] != cur:\n",
    "            if cur is not None:\n",
    "                if seq[-1][1] < max_stop:\n",
    "                    seq.append((seq[-1][0], max_stop))\n",
    "                seqs.append(seq)\n",
    "            seq = list()\n",
    "            cur = row[\"id\"]\n",
    "            seq.append((src, float(row[\"Tstart\"])))\n",
    "            feats.append(np.concatenate((\n",
    "                #match_map[row[\"match\"]],\n",
    "                #proph_map[row[\"proph\"]],\n",
    "                year_map[row[\"year\"]],\n",
    "                agecl_map[row[\"agecl\"]],\n",
    "                rng.normal(size=(5,))\n",
    "            )))\n",
    "        if row[\"status\"] == \"1\":\n",
    "            seq.append((dst, float(row[\"Tstop\"])))\n",
    "        max_stop = float(row[\"Tstop\"])\n",
    "    seqs.append(seq)\n",
    "\n",
    "# Indices of sequences that are > 180 days.\n",
    "idx = [seq[-1][1] > 1800 for seq in seqs]\n",
    "\n",
    "seqs = np.array(seqs, dtype=object)[idx]\n",
    "feats = np.array(feats, dtype=float)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(seqs)\n",
    "n = 6\n",
    "t0 = 60\n",
    "tf = 1800\n",
    "\n",
    "rng = np.random.default_rng(seed=1)\n",
    "idx = rng.permutation(len(seqs))\n",
    "\n",
    "seqs = seqs[idx]\n",
    "xs = feats[idx]\n",
    "ks, ts = summarize_sequences(seqs, n)\n",
    "(ks_offset, ts_offset), _ = summarize_sequences(seqs, n, split=t0)\n",
    "\n",
    "mask = ks.sum(axis=0).astype(bool)\n",
    "\n",
    "states_t0 = np.zeros((m, n))\n",
    "states_tf = np.zeros((m, n))\n",
    "\n",
    "for i, seq in enumerate(seqs):\n",
    "    prv_state = None\n",
    "    for state, t in seq:\n",
    "        if t > t0 and states_t0[i].sum() == 0.0:\n",
    "            states_t0[i, prv_state] = 1.0\n",
    "        if t > tf and states_tf[i].sum() == 0.0:\n",
    "            states_tf[i, prv_state] = 1.0\n",
    "        prv_state = state\n",
    "\n",
    "n_splits = 10\n",
    "zs = np.linspace(0, len(seqs), num=(n_splits + 1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(pred, actual):\n",
    "    \"\"\"Compute log-loss.\"\"\"\n",
    "    return np.sum(np.clip(-np.log(pred), None, 1e6) * actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/8rf5t6090bg06qjy19qcb8b00000gn/T/ipykernel_7858/567717744.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.clip(-np.log(pred), None, 1e6) * actual)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 19.5 s, total: 2min 46s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1 = CTMC(mask)\n",
    "tot = 0.0\n",
    "tmp = list()\n",
    "\n",
    "for i, (z1, z2) in enumerate(zip(zs[:-1], zs[1:])):\n",
    "    ks_train = np.concatenate((ks[:z1], ks[z2:]))\n",
    "    ts_train = np.concatenate((ts[:z1], ts[z2:]))\n",
    "    xs_train = np.concatenate((xs[:z1], xs[z2:]))\n",
    "    # CTMC\n",
    "    model1.fit(ks_train, ts_train, xs=xs_train, l2=3.0, verbose=False)\n",
    "    pred = model1.predict(states_t0[z1:z2], xs=xs[z1:z2], t=(tf - t0))\n",
    "    tot += log_loss(pred, states_tf[z1:z2])\n",
    "    tmp.append(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0431594319636326\n"
     ]
    }
   ],
   "source": [
    "res[\"ctmc\"] = tot / m\n",
    "print(res[\"ctmc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/8rf5t6090bg06qjy19qcb8b00000gn/T/ipykernel_7858/567717744.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.clip(-np.log(pred), None, 1e6) * actual)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "CPU times: user 6min 25s, sys: 1min 49s, total: 8min 14s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = GamMixCTMC(mask)\n",
    "tot_no = 0.0\n",
    "tot_wo = 0.0\n",
    "\n",
    "for i, (z1, z2) in enumerate(zip(zs[:-1], zs[1:])):\n",
    "    ks_train = np.concatenate((ks[:z1], ks[z2:]))\n",
    "    ts_train = np.concatenate((ts[:z1], ts[z2:]))\n",
    "    xs_train = np.concatenate((xs[:z1], xs[z2:]))\n",
    "    model2.fit(ks_train, ts_train, xs=xs_train, l2=3.0, verbose=False)\n",
    "    # No offsets.\n",
    "    pred = model2.predict(\n",
    "        states_t0[z1:z2],\n",
    "        xs=xs[z1:z2],\n",
    "        t=(tf - t0),\n",
    "        n_samples=100,\n",
    "    ).block_until_ready()\n",
    "    tot_no += log_loss(pred, states_tf[z1:z2])\n",
    "    # With offsets.\n",
    "    pred = model2.predict(\n",
    "        states_t0[z1:z2],\n",
    "        xs=xs[z1:z2],\n",
    "        t=(tf - t0),\n",
    "        n_samples=100,\n",
    "        offset=(ks_offset[z1:z2], ts_offset[z1:z2]),\n",
    "    ).block_until_ready()\n",
    "    tot_wo += log_loss(pred, states_tf[z1:z2])\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072854221321921\n",
      "0.6166308245249096\n"
     ]
    }
   ],
   "source": [
    "res[\"gammix-no\"] = tot_no / m\n",
    "res[\"gammix-wo\"] = tot_wo / m\n",
    "print(res[\"gammix-no\"])\n",
    "print(res[\"gammix-wo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "CPU times: user 1h 58min 50s, sys: 2h 56min 34s, total: 4h 55min 25s\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model3 = FiniteMixCTMC(mask, n_comps=5)\n",
    "tot_no = 0.0\n",
    "tot_wo = 0.0\n",
    "\n",
    "for i, (z1, z2) in enumerate(zip(zs[:-1], zs[1:])):\n",
    "    ks_train = np.concatenate((ks[:z1], ks[z2:]))\n",
    "    ts_train = np.concatenate((ts[:z1], ts[z2:]))\n",
    "    xs_train = np.concatenate((xs[:z1], xs[z2:]))\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        model3.fit(ks_train, ts_train, xs=xs_train, l2=1.5, seed=0, verbose=False)\n",
    "        # No offsets.\n",
    "        pred = model3.predict(\n",
    "            states_t0[z1:z2],\n",
    "            xs=xs[z1:z2],\n",
    "            t=(tf - t0),\n",
    "        ).block_until_ready()\n",
    "        tot_no += log_loss(pred, states_tf[z1:z2])\n",
    "        # With offsets.\n",
    "        pred = model3.predict(\n",
    "            states_t0[z1:z2],\n",
    "            xs=xs[z1:z2],\n",
    "            t=(tf - t0),\n",
    "            offset=(ks_offset[z1:z2], ts_offset[z1:z2]),\n",
    "        ).block_until_ready()\n",
    "        tot_wo += log_loss(pred, states_tf[z1:z2])\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6047254040055374\n",
      "0.7864194385405932\n"
     ]
    }
   ],
   "source": [
    "res[\"finmix-no\"] = tot_no / m\n",
    "res[\"finmix-wo\"] = tot_wo / m\n",
    "print(res[\"finmix-no\"])\n",
    "print(res[\"finmix-wo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----------|-----------|-----------|\n",
      "| Model     | no offset | w/ offset |\n",
      "|-----------|-----------|-----------|\n",
      "| DTMC      |     1.043 |     1.043 |\n",
      "| Inf. mix. |     0.907 |     0.617 |\n",
      "| Fin. mix. |     1.605 |     0.786 |\n",
      "|-----------|-----------|-----------|\n"
     ]
    }
   ],
   "source": [
    "print(\"|-----------|-----------|-----------|\")\n",
    "print(\"| Model     | no offset | w/ offset |\")\n",
    "print(\"|-----------|-----------|-----------|\")\n",
    "print(\"| DTMC      |     {:.3f} |     {:.3f} |\".format(res[\"ctmc\"], res[\"ctmc\"]))\n",
    "print(\"| Inf. mix. |     {:.3f} |     {:.3f} |\".format(res[\"gammix-no\"], res[\"gammix-wo\"]))\n",
    "print(\"| Fin. mix. |     {:.3f} |     {:.3f} |\".format(res[\"finmix-no\"], res[\"finmix-wo\"]))\n",
    "print(\"|-----------|-----------|-----------|\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
